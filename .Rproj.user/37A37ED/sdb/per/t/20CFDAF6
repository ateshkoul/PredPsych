{
    "collab_server" : "",
    "contents" : "#' Permutation Analysis for classification\n#'\n#' simple function to create permutation testing of a classifier\n#' \n#' @param Data            (dataframe) dataframe of the data\n#' @param predictorCol    (numeric) column number that contains the variable to be predicted\n#' @param selectedCols    (optional) (numeric) all the columns of data that would be used either as predictor or as feature\n#' @param classifierFun   (optional) (function) classifier function\n#' @param nSims           (optional) (numeric) number of simulations\n#'\n#' @return Returns \\code{actualAcc} of the classification analysis,\n#'  \\code{p-value} from permutation testing, \\code{nullAcc} distribution of the permutation \\code{figure} containing null distribution\n#'\n#'@author\n#'Atesh Koul, C'MON group, Istituto Italiano di technologia\n#'\n#'\\email{atesh.koul@@gmail.com}\nClassPerm <- function(Data,predictorCol,selectedCols,classifierFun,nSims=1000,...){\n  # classifierFun is a function that the use inputs to calculate the permutation scores\n  # The form of this function should return accuracy as a single value.\n  # Extra options should be specified in the classifier function\n  # Sample classifier function\n  # load libraries\n  library(caret)\n  library(ggplot2)\n  library(plotly)\n  library(plyr)\n\n  # a bit complicated to implement a generic way to feed in variable arguements\n  # match variable input\n  # extras <- match.call(expand.dots= F)$...\n  if(missing(selectedCols))  selectedCols <- 1:length(names(Data))\n  \n  selectedColNames <- names(Data)[selectedCols]\n  # get feature columns without response\n  featureColNames <- selectedColNames[-grep(names(Data)[predictorCol],selectedColNames)]\n  \n  # X <- Data[,featureColNames]\n  # Y <- Data[predictor]\n  \n  if (missing(classifierFun)){\n    \n    # if missing, use the default function of classifyFun from the library with default of svm\n    classifierFun <- classifyFun\n  }\n  # else {\n  #   print(classifierFun)\n  #   classifierFun <- get(classifierFun)\n  # }\n\n  # if your targets are not factors, make them..\n  if(!(is.factor(Data[,predictorCol]))) Data[,predictorCol] <- factor(Data[,predictorCol])\n  \n  set.seed(123)\n  print(\"Performing Cross Validation\")\n  # First calculate actual accuracy\n  actualAcc <- classifierFun(Data,predictorCol,selectedCols,...)\n  # calculate permutation scores by randomly sampling targets\n  chanceAcc <- 1/(length(unique(Data[,predictorCol])))\n  # permutator is a simple function that randomly shuffles targets and spits out accuracies\n  permutator <-function(Data,predictorCol,selectedCols){\n    Data[,predictorCol] <- sample(Data[,predictorCol])\n    # use silence to not print the accuracies multiple times\n    NullAcc <- classifierFun(Data,predictorCol,selectedCols,silent=TRUE,...)\n    return(NullAcc)\n  }\n\n  print(\"Performing permutation testing...\")\n  # default to 1000 repetitions\n  if(!exists(\"nSims\")) nSims <- 1000\n\n  print(paste0('performing ',nSims,' simulations'))\n  # important to set seed here not only for reproducibility\n  # also so that we don't get same results over and over again if\n  # we set seed in the classification function\n  #set.seed(111)\n\n  distNull <- data.frame(nullAcc=unlist(rlply(nSims, permutator(Data,predictorCol,selectedCols),.progress = progress_time())))\n  p_value = sum(distNull$nullAcc >= actualAcc)\n\n  # plot with automatically adjusting the height of the y-axis using 1 sd of the data\n  plot <- ggplot(distNull,aes(nullAcc))+\n    #geom_line(aes(x = c(actualAcc,actualAcc),y=c(0,max(density(dframe$x)$y)+ sd(density(dframe$x)$y))),data=dataActual)+\n    geom_vline(xintercept = actualAcc,colour='red')+\n    geom_vline(xintercept = chanceAcc,colour='red')+\n    geom_density(fill='darkblue',alpha=0.3)+\n    ggtitle(\"Permutation curve\") +\n#     geom_curve(x = actualAcc-0.18, xend = actualAcc-0.01, y = max(density(distNull$nullAcc)$y)-0.03,\n#                yend = max(density(distNull$nullAcc)$y)-0.5,curvature = 0.2,\n#                arrow = grid::arrow(length = grid::unit(0.03, \"npc\")))+\n    #   annotate(\"text\", x = actualAcc-0.18,y = max(density(distNull$nullAcc)$y)+0.1,\n    #                       colour=\"blue\", label = paste0('Actual Accuracy ',as.character(signif(actualAcc,2))),size=5)+\n    annotate(\"text\", x = actualAcc-0.03,y = 0.2,\n             colour=\"blue\", label = as.character(signif(actualAcc,2)),size=4)+\n    annotate(\"text\", x = chanceAcc-0.03,y = 0.2,\n             colour=\"blue\", label = 'chance',size=4)+\n    theme_bw(base_size = 18)+\n    theme(axis.line = element_line(colour = \"black\"),\n          panel.grid.major = element_blank(),\n          panel.grid.minor = element_blank(),\n          panel.background = element_blank(),\n          panel.border = element_blank(),\n          axis.line.y = element_line(color = 'black'),\n          axis.line.x = element_line(color = 'black'))+\n    scale_y_continuous(expand = c(0, 0), limits = c(0, max(density(distNull$nullAcc)$y)+ 0.3*sd(density(distNull$nullAcc)$y))) +\n    scale_x_continuous(expand = c(0.01, 0.01), limits = c(-0.1, 1.01))\n\n  print(ggplotly(plot))\n  Results = list(actualAcc = actualAcc,p_value=p_value,nullAcc = distNull$nullAcc,plot=plot,distNull= distNull)\n  return(Results)\n\n}\n\n\nLinearDAPerm <- function(X,Y,cvType=\"LOTO\"){\n  #simple function to perform linear discriminant analysis\n  # DOn't set seed here as it goes back to the permutator function and constraints the sample \n  # to set the same value for Y over and over again.\n  library(MASS)\n  library(caret)\n  if(cvType==\"LOTO\"){\n    index <- createFolds(Y,k=length(Y),list=FALSE)\n    acc <- vector()\n    \n    for(i in seq_along(index)){\n      XTrain <- X[-i,]\n      YTrain <- Y[-i]\n      XTest <-  X[i,]\n      YTest <-  Y[i]\n      fit <- lda(XTrain,grouping = YTrain)\n      predicted <- predict(fit,newdata=XTest)\n      #print(table(predicted$class,DataTest[,predictorCol]))\n      acc[i] <- sum(1 * (predicted$class==YTest))/length(predicted$class)\n    }\n    Acc <- mean(acc)\n    #print(paste(\"The accuracy of discrimination was\",signif(Acc,2)))\n  }  \n  \n  return(Acc)\n  \n  \n}\n\n\nLinearSVM <- function(X,Y){\n  # a simplistic k-fold crossvalidation\n  # For cross validation\n  library(e1071)\n  #set.seed(111)\n  # defaults to 10 fold cross validation\n  k = 10\n  # use stratified cross validation instead\n  # use 80% data for training\n  trainIndex <- createFolds(Y, list = FALSE,k = k)\n  acc <- rep(NA,k)\n  for (i in 1:k){\n    trainX <- X[!trainIndex==i,]\n    testX <- X[trainIndex==i,]\n    trainY <- Y[!trainIndex==i]\n    testY <- Y[trainIndex==i]\n    model <- svm(trainX, trainY,kernel = \"linear\")\n    # test with train data\n    pred <- predict(model, testX)\n    acc[i] <- sum(1 * (pred==testY))/length(pred)\n  }\n  \n  # old Method\n  \n  #       folds <- cvFolds(nrow(X),K = k)\n  #       acc <- rep(NA,k)\n  #\n  #       for (i in 1:k){\n  #         trainX <- X[folds$subsets[folds$which != i], ]\n  #         testX <- X[folds$subsets[folds$which == i], ]\n  #         trainY <- Y[folds$subsets[folds$which != i]]\n  #         testY <- Y[folds$subsets[folds$which == i]]\n  #         model <- svm(trainX, trainY,kernel = \"linear\")\n  #         # test with train data\n  #         pred <- predict(model, testX)\n  #         acc[i] <- sum(1 * (pred==testY))/length(pred)\n  #       }\n  return(mean(acc,na.rm=T))\n}",
    "created" : 1469535433561.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2679520824",
    "id" : "20CFDAF6",
    "lastKnownWriteTime" : 1469540968,
    "last_content_update" : 1469540968035,
    "path" : "D:/SVNWorkingDir/CMON/ReadingIntention/CommonScripts/PredPsych/R/ClassPerm.R",
    "project_path" : "R/ClassPerm.R",
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}